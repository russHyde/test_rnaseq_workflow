import pandas as pd
import yaml
from os.path import join

from snakemake.utils import min_version
from snakemake.utils import validate

# validate requires snakemake >= 5.1
# `conda activate` requires snakemake >= 5.4.3
min_version("5.4.3")

###############################################################################

# -- configuration

# ---- global snakemake config

validate(config, "conf_schemas/snake_config.schema.yaml")

# ---- definition of samples for study here

def define_sequencing_samples(filepath):
    sequencing_samples = pd.read_csv(
        filepath, sep = "\t", comment="#"
    ).set_index(
        ["study_id", "sample_id", "run_id", "lane_id"], drop = False
    )
    sequencing_samples.index = sequencing_samples.index.set_levels(
        [i.astype(str) for i in sequencing_samples.index.levels]
    )
    return sequencing_samples


sequencing_samples = define_sequencing_samples(config["sequencing_samples"])
validate(sequencing_samples, "conf_schemas/sequencing_samples.schema.yaml")

# ---- definition of command line params for the programs used here

program_params = yaml.safe_load(
    open(config["program_params"], "r")
)
validate(
    program_params, "conf_schemas/program_params.schema.yaml"
)

# ---- definition of the transcriptome / genome reference used here

reference_params = yaml.safe_load(
    open(config["reference_params"], "r")
)
validate(
    reference_params, "conf_schemas/reference_params.schema.yaml"
)

###############################################################################

# -- data directories

job_dir = join("data", "job")

read_dirs = {
    "raw" : join(job_dir, "reads", "raw_fastqs"),
    "trimmed": join(job_dir, "reads", "trimmed_fastqs")
}

# -- required files

# This ensures that the feature-counts for each sequencing sample on each lane
# are obtained:

trimmed_fastq_files = expand(
    join(
        read_dirs["trimmed"], "{unit.study_id}", "{unit.sample_id}",
        "{unit.run_id}_{unit.lane_id}_{read}.fastq.gz"
    ),
    unit=sequencing_samples.itertuples(),
    read=[1, 2]
)

feature_counts_files = expand(
    join(
        "data", "job", "align", "{unit.study_id}", "{unit.sample_id}",
        "{unit.run_id}_{unit.lane_id}.fcount.short"
    ),
    unit=sequencing_samples.itertuples()
)

required_files = feature_counts_files

# -- rules

rule all:
    input:
        required_files

rule fake_trimming_and_alignment_report:
    input:
        feature_counts_files
    output:
        "doc/fake_report.pdf"
    shell:
        "touch {output}"

# -- rule-defining scripts

include: "scripts/snake_recipes/access_raw_reads.smk"
include: "scripts/snake_recipes/trim_cutadapt.smk"
include: "scripts/snake_recipes/align_hisat2.smk"
include: "scripts/snake_recipes/quantify_subread.smk"
