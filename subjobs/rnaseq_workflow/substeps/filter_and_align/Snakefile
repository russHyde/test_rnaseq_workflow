import pandas as pd
import yaml
from os.path import join

from snakemake.utils import min_version
from snakemake.utils import validate

# validate requires snakemake >= 5.1
# `conda activate` requires snakemake >= 5.4.3
min_version("5.4.3")

###############################################################################

# -- configuration

# ---- global snakemake config

validate(config, "conf_schemas/snake_config.schema.yaml")

# ---- definition of samples for study here

def define_sequencing_samples(filepath):
    sequencing_samples = pd.read_csv(
        filepath, sep = "\t", comment="#"
    ).set_index(
        ["study_id", "sample_id", "run_id", "lane_id"], drop = False
    )
    sequencing_samples.index = sequencing_samples.index.set_levels(
        [i.astype(str) for i in sequencing_samples.index.levels]
    )
    return sequencing_samples


sequencing_samples = define_sequencing_samples(config["sequencing_samples"])
validate(sequencing_samples, "conf_schemas/sequencing_samples.schema.yaml")

# ---- definition of command line params for the programs used here

program_params = yaml.safe_load(
    open(config["program_params"], "r")
)
validate(
    program_params, "conf_schemas/program_params.schema.yaml"
)

# ---- definition of the transcriptome / genome reference used here

reference_params = yaml.safe_load(
    open(config["reference_params"], "r")
)
validate(
    reference_params, "conf_schemas/reference_params.schema.yaml"
)

###############################################################################

# -- data directories

job_dir = join("data", "job")

read_dirs = {
    "prefix": join(job_dir, "reads"),
    "raw" : join(job_dir, "reads", "raw_fastqs"),
    "trimmed": join(job_dir, "reads", "trimmed_fastqs")
}

fastqc_dirs = {
    "prefix": join(job_dir, "fastqc"),
    "raw": join(job_dir, "fastqc", "raw_fastqs"),
    "trimmed": join(job_dir, "fastqc", "trimmed_fastqs")
}

# -- required files

# Make a separate fastqc report for both raw and trimmed fastq files from each
# sample, run and read direction

fastqc_reports = expand(
    join(
        "{directory_prefix}", "{unit.study_id}", "{unit.sample_id}",
        "{unit.run_id}_{unit.lane_id}_{read}_fastqc.{ext}"
    ),
    directory_prefix=[fastqc_dirs["raw"], fastqc_dirs["trimmed"]],
    unit=sequencing_samples.itertuples(),
    read=[1, 2],
    ext=["html", "zip"]
)

# This ensures that the feature-counts for each sequencing sample on each lane
# are obtained:

feature_counts_files = expand(
    join(
        "{directory_prefix}", "{unit.study_id}", "{unit.sample_id}",
        "{unit.run_id}_{unit.lane_id}.fcount.short"
    ),
    directory_prefix=[os.path.join(job_dir, "align")],
    unit=sequencing_samples.itertuples()
)

required_files = \
    feature_counts_files + \
    fastqc_reports

# -- rules

rule all:
    input:
        required_files

rule fake_trimming_and_alignment_report:
    input:
        required_files
    output:
        "doc/fake_report.pdf"
    shell:
        "touch {output}"

# -- rule-defining scripts

include: "scripts/snake_recipes/access_raw_reads.smk"
include: "scripts/snake_recipes/trim_cutadapt.smk"
include: "scripts/snake_recipes/align_hisat2.smk"
include: "scripts/snake_recipes/quantify_subread.smk"
include: "scripts/snake_recipes/quality_fastqc.smk"
